{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1 - Linear Regression\n",
    "- [Linear regression with one variable](#Linear-regression-with-one-variable)\n",
    "- [Gradient Descent](#Gradient-Descent)\n",
    "- Submission deadline August, 11, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%config InlineBackend.figure_formats = {'pdf',}\n",
    "%matplotlib inline \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "pd.set_option('display.max_seq_items', None)\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression with one variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bfd54c9330bebdb71cbd3174355f8d93",
     "grade": true,
     "grade_id": "q1",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#read Assingment1data1.txt  file  with numpy\n",
    "# YOUR CODE HERE\n",
    "X = np.c_[np.ones(data.shape[0]),data[:,0]]\n",
    "y = np.c_[data[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85e84ac6a2d41d94870ab738d050b4b9",
     "grade": false,
     "grade_id": "w1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# read Assingment1data1.txt file  with numpy\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "X = np.c_[np.ones(data.shape[0]),data[:,0]]\n",
    "y = np.c_[data[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "094ec3ecd0dfab05bd3205a6bf6c73eb",
     "grade": true,
     "grade_id": "q2",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# scatter plot of  X[:,1] vs y  with read color, marker * and lineweidth of 1\n",
    "\n",
    "# YOUR CODE HERE\n",
    "plt.xlim(4,24)\n",
    "plt.xlabel('Population of City in 10,000s')\n",
    "plt.ylabel('Profit in $10,000s');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bdbc5dbbf554a359bf48f32e923365fe",
     "grade": false,
     "grade_id": "w2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# SCATER PLOT WITH READ COLOR, * MARKDER, AND LINEWIDTH ONE OF X[:,1] vs y\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "plt.xlim(4,24)\n",
    "plt.xlabel('Population of City in 10,000s')\n",
    "plt.ylabel('Profit in $10,000s');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent\n",
    "\n",
    "In this section, you will fit the linear regression parameters Î¸ to our dataset using gradient descent. The objective of linear regression is to minimize the cost function:\n",
    "$$J(\\mathbf{\\theta_0}) = \\frac{1}{2m} \\sum_{i=1}^{m}\\left(h_\\theta({x}^{i}) - y^{(i)}\\right)^2$$\n",
    "\n",
    "where the hypothesis $h_{\\theta}(x))$ is given by:\n",
    "$$h_{\\theta}(x) = \\theta_0 + \\theta_1x = \\theta^{T}x$$\n",
    "\n",
    " One way to do the parameters $\\theta_j$ valis to use the batch gradient descent algorithm. In batch gradient descent, each iteration performs the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "000191d126839f2a4c3c2f7479ed9a14",
     "grade": true,
     "grade_id": "q3",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Represent the hypothesis and cost function using m,X,y and theta, and h\n",
    "def computeCost(X, y, theta=[[0],[0]]):\n",
    "    m = y.size\n",
    "    J = 0\n",
    "    # YOUR CODE HERE\n",
    "    return(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8deb2c9640f2d5abf6e994383c86344",
     "grade": false,
     "grade_id": "w3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# \n",
    "def computeCost(X, y, theta=[[0],[0]]):\n",
    "    m = y.size\n",
    "    J = 0\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeCost(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d95c50b33dc74f91a3b32a6e1d7db65",
     "grade": true,
     "grade_id": "q4",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "write a gradiet denscent function to update theta and J using gradient desent method \n",
    "with stepsize=0.01 for 1500 iterations\n",
    "'''\n",
    "def gradientDescent(X, y, theta=[[0],[0]], alpha=0.01, num_iters=1500):\n",
    "    m = y.size\n",
    "    J_history = np.zeros(num_iters)\n",
    "    for iter in np.arange(num_iters):\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "    return(theta, J_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08fbbc7964ce434acc0b2658bb7ce5dc",
     "grade": false,
     "grade_id": "w4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# write a gradiet denscent function to update theta and J using gradient desent method \n",
    "#with stepsize=0.01 for 1500 iterations\n",
    "def gradientDescent(X, y, theta=[[0],[0]], alpha=0.01, num_iters=1500):\n",
    "    m = y.size\n",
    "    J_history = np.zeros(num_iters)\n",
    "    for iter in np.arange(num_iters):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    return(theta, J_history)\n",
    "\n",
    "# theta for minimized cost J\n",
    "theta , Cost_J = gradientDescent(X, y)\n",
    "print('theta: ',theta.ravel())\n",
    "\n",
    "plt.plot(Cost_J)\n",
    "plt.ylabel('Cost J')\n",
    "plt.xlabel('Iterations');\n",
    "\n",
    "assert theta == [-3.63029144  1.16636235]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4677310b78d88b909207bcb31299b8cd",
     "grade": true,
     "grade_id": "q5",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "we can use a scatter plot to visualize the data, since it has only two properties \n",
    "to plot (profit and population).\n",
    "'''\n",
    "xx = np.arange(5,23)\n",
    "yy = theta[0]+theta[1]*xx\n",
    "\n",
    "# scatter plot of  X[:,1] vs y  with read color, marker * and lineweidth of 1\n",
    "#YOUR CODE HERE\n",
    "plt.plot(xx,yy, label='Linear regression (Gradient descent)')\n",
    "# Compare with Scikit-learn Linear regression \n",
    "regr = LinearRegression()\n",
    "regr.fit(X[:,1].reshape(-1,1), y.ravel())\n",
    "plt.plot(xx, regr.intercept_+regr.coef_*xx, label='Linear regression (Scikit-learn GLM)')\n",
    "\n",
    "plt.xlim(4,24)\n",
    "plt.xlabel('Population of City in 10,000s')\n",
    "plt.ylabel('Profit in $10,000s')\n",
    "plt.legend(loc=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cbec6359a979e7fc4002defe99071f5d",
     "grade": false,
     "grade_id": "w5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "xx = np.arange(5,23)\n",
    "yy = theta[0]+theta[1]*xx\n",
    "\n",
    "#  scatter plot of  X[:,1] vs y  with read color, marker * and lineweidth of 1\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "plt.plot(xx,yy, label='Linear regression (Gradient descent)')\n",
    "# Compare with Scikit-learn Linear regression \n",
    "regr = LinearRegression()\n",
    "regr.fit(X[:,1].reshape(-1,1), y.ravel())\n",
    "plt.plot(xx, regr.intercept_+regr.coef_*xx, label='Linear regression (Scikit-learn GLM)')\n",
    "\n",
    "plt.xlim(4,24)\n",
    "plt.xlabel('Population of City in 10,000s')\n",
    "plt.ylabel('Profit in $10,000s')\n",
    "plt.legend(loc=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict profit for a city with population of 35000 and 70000\n",
    "print(theta.T.dot([1, 3.5])*10000)\n",
    "print(theta.T.dot([1, 7])*10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid coordinates for plotting\n",
    "B0 = np.linspace(-10, 10, 50)\n",
    "B1 = np.linspace(-1, 4, 50)\n",
    "xx, yy = np.meshgrid(B0, B1, indexing='xy')\n",
    "Z = np.zeros((B0.size,B1.size))\n",
    "\n",
    "# Calculate Z-values (Cost) based on grid of coefficients\n",
    "for (i,j),v in np.ndenumerate(Z):\n",
    "    Z[i,j] = computeCost(X,y, theta=[[xx[i,j]], [yy[i,j]]])\n",
    "\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "\n",
    "# Left plot\n",
    "CS = ax1.contour(xx, yy, Z, np.logspace(-2, 3, 20), cmap=plt.cm.jet)\n",
    "ax1.scatter(theta[0],theta[1], c='r')\n",
    "\n",
    "# Right plot\n",
    "ax2.plot_surface(xx, yy, Z, rstride=1, cstride=1, alpha=0.6, cmap=plt.cm.jet)\n",
    "ax2.set_zlabel('Cost')\n",
    "ax2.set_zlim(Z.min(),Z.max())\n",
    "ax2.view_init(elev=15, azim=230)\n",
    "\n",
    "# settings common to both plots\n",
    "for ax in fig.axes:\n",
    "    ax.set_xlabel(r'$\\theta_0$', fontsize=17)\n",
    "    ax.set_ylabel(r'$\\theta_1$', fontsize=17)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
